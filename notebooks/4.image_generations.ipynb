{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9e86b-396e-413e-9cc6-32fcb11cd3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b40005e-c1be-4b4e-b58f-7edded7979b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, f'../../')\n",
    "sys.path.insert(0, f'../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87bd7b2-4c11-4cc5-9ad3-80545bc3fc0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchmetrics.functional import (\n",
    "    structural_similarity_index_measure,\n",
    "    peak_signal_noise_ratio,\n",
    ")\n",
    "\n",
    "import clip\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7029cb0-86b5-41ed-a84b-83dbdf6b8083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clip model setup\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c0f80-2820-47b2-80f6-ee3f42052fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = preprocess(Image.open(\"./outputs/base_ScubaDiver.jpg\")).unsqueeze(0).to(device)\n",
    "text = clip.tokenize(    [\"Vibrant and vivid\", \"Dull and washed-out\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "\n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a09966-1f74-4d35-ada0-dd80202acd3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from waternet.data import transform as preprocess_transform\n",
    "from waternet.training_utils import arr2ten\n",
    "from waternet.net import WaterNet\n",
    "from configs.constants import contrastive_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea32dc5a-8be1-4bdd-bb62-30aa4aeedaa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def arr2ten_noeinops(arr):\n",
    "    \"\"\"Converts (N)HWC numpy array into torch Tensor:\n",
    "    1. Divide by 255\n",
    "    2. Rearrange dims: HWC -> 1CHW or NHWC -> NCHW\n",
    "    \"\"\"\n",
    "    ten = torch.from_numpy(arr) / 255\n",
    "    if len(ten.shape) == 3:\n",
    "        # ten = rearrange(ten, \"h w c -> 1 c h w\")\n",
    "        ten = torch.permute(ten, (2, 0, 1))\n",
    "        ten = torch.unsqueeze(ten, dim=0)\n",
    "    elif len(ten.shape) == 4:\n",
    "        # ten = rearrange(ten, \"n h w c -> n c h w\")\n",
    "        ten = torch.permute(ten, (0, 3, 1, 2))\n",
    "    return ten\n",
    "\n",
    "def pre_process(rgb_arr, ref):\n",
    "    wb, gc, he = preprocess_transform(rgb_arr)\n",
    "    rgb_ten = arr2ten_noeinops(rgb_arr)\n",
    "    wb_ten = arr2ten_noeinops(wb)\n",
    "    gc_ten = arr2ten_noeinops(gc)\n",
    "    he_ten = arr2ten_noeinops(he)\n",
    "    ref_ten = arr2ten_noeinops(ref)\n",
    "    return rgb_ten, wb_ten, he_ten, gc_ten, ref_ten\n",
    "    \n",
    "def post_process(ten):\n",
    "    arr = ten.cpu().detach().numpy()\n",
    "    arr = np.clip(arr, 0, 1)\n",
    "    # arr = arr - np.min(arr)\n",
    "    # arr = arr / np.max(arr)\n",
    "    arr = (arr * 255).astype(np.uint8)\n",
    "    # arr = rearrange(arr, \"n c h w -> n h w c\")\n",
    "    arr = np.transpose(arr, (0, 2, 3, 1))\n",
    "    return arr\n",
    "\n",
    "def process(img, waternet):\n",
    "    rgb_ten, wb_ten, he_ten, gc_ten, _ = pre_process(img, img)\n",
    "    rgb_ten, wb_ten, he_ten, gc_ten = rgb_ten.to(device), wb_ten.to(device), he_ten.to(device), gc_ten.to(device)\n",
    "    out_ten = waternet(rgb_ten, wb_ten, he_ten, gc_ten)\n",
    "    return post_process(out_ten)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09891db-1e51-460b-af65-4ce7b8354082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WB, CL, LIT\n",
    "WB = [0, 1, 2]\n",
    "CL = [3, 4]\n",
    "LIT = [5, 6]\n",
    "\n",
    "flatten_pairs = np.ravel(contrastive_pairs)\n",
    "good_prompts = flatten_pairs[::2]\n",
    "WB_prompts = good_prompts[WB]\n",
    "CL_prompts = good_prompts[CL]\n",
    "LIT_prompts = good_prompts[LIT]\n",
    "\n",
    "print(WB_prompts)\n",
    "print(CL_prompts)\n",
    "print(LIT_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6fefd4-da11-435c-8571-671cf55a9d81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kinds = {\n",
    "    \"base\": \"weights/pretrained/waternet.pt\",\n",
    "    \"vivid_mid\": \"weights/color-enhanced.pt\",\n",
    "    \"color_cast\": \"weights/wb-enhanced.pt\",\n",
    "    \"exposure\": \"weights/expo-enhanced.pt\",\n",
    "    \"all\": \"weights/all-enhanced.pt\",\n",
    "}\n",
    "\n",
    "waternets = []\n",
    "for _, key in enumerate(kinds):\n",
    "    waternet = WaterNet()\n",
    "    check_point = torch.load(f'../{kinds[key]}')\n",
    "    waternet.load_state_dict(check_point)\n",
    "    waternet.eval()\n",
    "    waternet = waternet.to(device)\n",
    "    waternets.append(waternet)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSUI Dataset Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f82704472c3b6d9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d6804-87a0-42fc-9534-45ad2089e832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need setup lsui data set first: get_data(\"lsui\")\n",
    "lsui_files = os.listdir(\"./lsui/GT\")\n",
    "lsui_files.sort(key=lambda x:int(x[:-4]))\n",
    "lsui_gts = [os.path.join(\"./lsui/GT\", _) for _ in lsui_files]\n",
    "lsui_raws = [os.path.join(\"./lsui/input\", _) for _ in lsui_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea410d8a-24bd-44f6-8735-912b81acca03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "output_directory = './lsui/'\n",
    "for kind, _ in kinds.items():\n",
    "    csv_file_path = os.path.join(output_directory, f\"{kind}_results.csv\")\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    dfs[kind] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef507ab8-5690-4a21-88b2-fc916c466c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(kind, raw_path):\n",
    "    basename = os.path.basename(raw_path)\n",
    "    path = f'./lsui/{kind}/{basename}'\n",
    "    img = cv2.imread(path)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def display_images(raw_path, gt_path=None, _load_image=True, _save_image=False):\n",
    "    basename = os.path.basename(raw_path)\n",
    "    raw = cv2.imread(raw_path)\n",
    "    raw = cv2.cvtColor(raw, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Prepare the figure\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(25, 18))\n",
    "    axs = axs.flatten()  # Flatten the array for easy indexing\n",
    "\n",
    "    # Display the source image\n",
    "    axs[0].imshow(raw)\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[0].set_title(\"Source\")\n",
    "    \n",
    "    offset = 1\n",
    "    \n",
    "    if gt_path is not None:\n",
    "        gt = cv2.imread(gt_path)\n",
    "        gt = cv2.cvtColor(gt, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axs[1].imshow(gt)\n",
    "        axs[1].axis(\"off\")\n",
    "        axs[1].set_title(\"ref\")\n",
    "        offset += 1\n",
    "    \n",
    "    # Process and display each kind\n",
    "    for index, kind in enumerate(kinds):\n",
    "        if _load_image:\n",
    "            img = load_image(kind, raw_path)\n",
    "        else:\n",
    "            img = process(raw, waternets[index])\n",
    "        axs[index+offset].imshow(img)\n",
    "        axs[index+offset].axis(\"off\")\n",
    "        axs[index+offset].set_title(kind)\n",
    "        \n",
    "        if _save_image:\n",
    "            path = f\"./outputs/\"\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "                print(f\"make dir path: {path}\")\n",
    "\n",
    "            output_image_path = f\"{path}/{kind}_{basename}\"\n",
    "            cv2.imwrite(output_image_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def save_image(raw_path, _load_image=True):\n",
    "    basename = os.path.basename(raw_path)\n",
    "    path = f\"./outputs/\"\n",
    "    img = cv2.imread(raw_path)\n",
    "    cv2.imwrite(path+f\"raw_{basename}\", img)\n",
    "    for index, kind in enumerate(kinds):\n",
    "        if _load_image:\n",
    "            img = load_image(kind, raw_path)\n",
    "        else:\n",
    "            img = process(img, waternets[index])\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            print(f\"make dir path: {path}\")\n",
    "\n",
    "        output_image_path = f\"{path}/{kind}_{basename}\"\n",
    "        cv2.imwrite(output_image_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4098c656-28f9-414c-9e00-905194577388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_show_images = [1211, 1311, 1395, 1636, 2902, 3090, 3151, 3198, 3222, 3331, 3357, 3456, 3645, 3937, 4008, 4992]\n",
    "limited = [2054, 2055, 2057]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc71bd-8bfd-409f-a98d-b877fa970525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ind in to_show_images:\n",
    "    raw_path = f\"./lsui/input/{ind}.jpg\"\n",
    "    save_image(raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db0d41-d4dd-4d9c-8337-3621fcc74c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the results\n",
    "picked_ = 4992\n",
    "raw_path = f\"./lsui/input/{picked_}.jpg\"\n",
    "gt_path = f\"./lsui/GT/{picked_}.jpg\"\n",
    "# raw_path = \"./ScubaDiver.jpg\"\n",
    "display_images(raw_path, _load_image=False, _save_image=False)#, gt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16b27d-70c1-447c-b5e8-dc382fe3b101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp39env",
   "language": "python",
   "name": "cp39env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
